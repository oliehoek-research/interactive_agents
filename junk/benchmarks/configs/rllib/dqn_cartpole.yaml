DQN_CartPole:
  run: DQN
  env: CartPole-v1
  stop:
    timesteps_total: 200000
  checkpoint_freq: 20
  num_samples: 8
  config:
    gamma: 0.99
    lr: 0.001
    # DEFAULTS
    # Default of 1 means we aren't doing distributional DQN
    num_atoms: 1
    # May want to expand this range for CartPole
    v_min: -10.0
    v_max: 10.0
    # Whether to use noisy network (there are additional parameters to tune if we do)
    noisy: False
    # Whether to use Dueling DQN
    dueling: True
    # Size of the separate advantage and value hidden layers used for dueling DQN
    hiddens: [256]
    # Whether to use Dueling DQN
    double_q: True
    # N-step Q learning
    n_step: 1
    # Prioretized experience replay parameters
    prioritized_replay: True
    prioritized_replay_alpha: 0.6
    prioritized_replay_beta: 0.4
    final_prioritized_replay_beta: 0.4
    prioritized_replay_beta_annealing_timesteps: 20000
    prioritized_replay_eps: 1.e-6  # NOTE: YAML requires a dot in the mantissa for scientific notation, otherwise gets parsed as a string