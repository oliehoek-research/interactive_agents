r2d2_memory_benchmark:
  stop:
    iterations: 8000
  trainer: independent
  num_seeds: 4
  config:
    max_steps: 500
    iteration_episodes: 32
    eval_episodes: 8
    env: memory
    env_config:
      length: 
        grid_search: [10, 20, 40, 80]
      num_cues:
        grid_search: [5, 10]
      noise: 0.0
    learner: R2D2
    learner_config:
      lr: 
        grid_search: [0.001, 0.01]
      dueling: True
      num_batches:
        grid_search: [16, 32]
      batch_size: 32
      sync_iterations:
        grid_search: [10, 20]
      learning_starts: 50
      gamma: 0.99
      beta: 0.5
      double_q: True
      epsilon_initial: 0.5
      epsilon_iterations: 7000
      epsilon_final: 0.01
      replay_alpha:
        grid_search: [0.6, 0.0]
      replay_epsilon: 0.01
      replay_eta: 0.5
      replay_beta_iterations: 7000
      buffer_size: 
        grid_search: [32768, 65536]
      dueling: True
      model: lstm
      model_config:
        hidden_size: 64
        hidden_layers: 1
